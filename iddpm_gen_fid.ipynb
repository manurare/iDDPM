{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<a href=\"https://colab.research.google.com/github/sndnyang/iDDPM/blob/master/iddpm_gen_fid.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
    "\n",
    "# iDDPM Generate and FID\n",
    "\n",
    "Generating/sampling new images and evaluate FID\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.10.7 64-bit' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'c:/Python310/python.exe -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# Download the pre-trained model from openAI iDDPM\n",
    "!wget https://openaipublic.blob.core.windows.net/diffusion/march-2021/cifar10_uncond_50M_500K.pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorboardX torch_fidelity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# If you are use colab, you can mount your Google Drive.\n",
    "# Otherwise, you need to upload the code?\n",
    "import sys\n",
    "\n",
    "sys.path.append('/drive/MyDrive/research/iDDPM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import argparse\n",
    "import numpy as np\n",
    "import torch.optim\n",
    "import torch.utils.data\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from ExpUtils import *\n",
    "from utils.dataloader import datainfo, dataload\n",
    "from eval_tasks import *\n",
    "from iddpm.script_util import create_model_and_diffusion, model_and_diffusion_defaults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.10.7 64-bit' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'c:/Python310/python.exe -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "\n",
    "arg = argparse.Namespace()\n",
    "arg.dataset = 'cifar10'\n",
    "arg.data_path = './data'\n",
    "arg.workers = 4\n",
    "arg.eval = 'nll'\n",
    "arg.resume = 'cifar10_uncond_50M_500K.pt'\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "arg.device = device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data_info = datainfo(logger, arg)\n",
    "\n",
    "if arg.eval == 'buffer':\n",
    "    buffer = torch.load(arg.resume, map_location=arg.device)\n",
    "    eval_buffer(buffer, arg)\n",
    "\n",
    "normalize = [transforms.Normalize(mean=data_info['stat'][0], std=data_info['stat'][1])]\n",
    "augmentations = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    *normalize\n",
    "])\n",
    "\n",
    "'''\n",
    "    model\n",
    "'''\n",
    "\n",
    "model, diffusion = create_model_and_diffusion(\n",
    "    **model_and_diffusion_defaults()\n",
    ")\n",
    "\n",
    "\n",
    "n_parameters = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f'Number of params: {format(n_parameters, \",\")}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_samples(model, diffusion, arg) in eval_tasks.py\n",
    "\n",
    "im_sz = arg.image_size\n",
    "start = time.time()\n",
    "batches = 100 if arg.dataset != 'stl10' else 50\n",
    "replay_buffer = torch.FloatTensor(batches * 100, n_ch, im_sz, im_sz).uniform_(-1, 1)\n",
    "eval_time = 0\n",
    "bs = 100\n",
    "\n",
    "# sample_fn = (\n",
    "#     diffusion.p_sample_loop if not arg.use_ddim else diffusion.ddim_sample_loop\n",
    "# )\n",
    "\n",
    "for i in range(batches):\n",
    "\n",
    "    samples = diffusion.p_sample_loop(\n",
    "        model, (bs, 3, im_sz, im_sz), clip_denoised=True, model_kwargs=None\n",
    "    )\n",
    "    replay_buffer[i * bs: (i + 1) * bs] = (samples + 1) / 2\n",
    "\n",
    "    if (i + 1) % 10 == 0:\n",
    "        now = time.time()\n",
    "        print(f'batch {i + 1} {str(timedelta(seconds=now - start - eval_time))}')\n",
    "\n",
    "    if (i + 1) in [1, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 200, 300, 400, 500]:\n",
    "        eval_start = time.time()\n",
    "        plot('{}/samples_{}.png'.format(arg.dir_path, i+1), samples)\n",
    "        metrics = eval_is_fid(replay_buffer[:(i + 1) * bs] * 255, dataset=arg.dataset, args=arg)\n",
    "        inc_score = metrics['inception_score_mean']\n",
    "        fid = metrics['frechet_inception_distance']\n",
    "        print(\"sample with %d\" % (i * bs + bs))\n",
    "        print(\"Inception score of {}\".format(inc_score))\n",
    "        print(\"FID of score {}\".format(fid))\n",
    "        eval_time += time.time() - eval_start"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
